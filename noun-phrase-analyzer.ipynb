{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import json\n",
    "from textblob import TextBlob, Word\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "import nltk\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file detected.\n",
      "First few lines of imported file:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTC DateTime</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Username</th>\n",
       "      <th>User Karma (total)</th>\n",
       "      <th>Parent Comment ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comment ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original Post</th>\n",
       "      <td>1.670429e+09</td>\n",
       "      <td>Retail theft at Walmart may lead to raised pri...</td>\n",
       "      <td>33022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Pazluz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zf54gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iza7on8</th>\n",
       "      <td>1.670432e+09</td>\n",
       "      <td>''Some markets are no longer worth having a pr...</td>\n",
       "      <td>9336</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>Xivvx</td>\n",
       "      <td>99326.0</td>\n",
       "      <td>t3_zf54gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>izc7ash</th>\n",
       "      <td>1.670461e+09</td>\n",
       "      <td>I work for Walmart . Not their retail side. Fo...</td>\n",
       "      <td>368</td>\n",
       "      <td>-0.050794</td>\n",
       "      <td>0.489365</td>\n",
       "      <td>Hrrrrnnngggg</td>\n",
       "      <td>85821.0</td>\n",
       "      <td>t3_zf54gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iza2635</th>\n",
       "      <td>1.670430e+09</td>\n",
       "      <td>They got rid of most the cashiers. That adds a...</td>\n",
       "      <td>14324</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Amy_Macadamia</td>\n",
       "      <td>30055.0</td>\n",
       "      <td>t3_zf54gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>izae8rg</th>\n",
       "      <td>1.670435e+09</td>\n",
       "      <td>LOL...Walmart's wages are so low that many of ...</td>\n",
       "      <td>5645</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>rucb_alum</td>\n",
       "      <td>30307.0</td>\n",
       "      <td>t3_zf54gb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               UTC DateTime  \\\n",
       "Comment ID                    \n",
       "Original Post  1.670429e+09   \n",
       "iza7on8        1.670432e+09   \n",
       "izc7ash        1.670461e+09   \n",
       "iza2635        1.670430e+09   \n",
       "izae8rg        1.670435e+09   \n",
       "\n",
       "                                                         Comment  Score  \\\n",
       "Comment ID                                                                \n",
       "Original Post  Retail theft at Walmart may lead to raised pri...  33022   \n",
       "iza7on8        ''Some markets are no longer worth having a pr...   9336   \n",
       "izc7ash        I work for Walmart . Not their retail side. Fo...    368   \n",
       "iza2635        They got rid of most the cashiers. That adds a...  14324   \n",
       "izae8rg        LOL...Walmart's wages are so low that many of ...   5645   \n",
       "\n",
       "               Polarity  Subjectivity       Username  User Karma (total)  \\\n",
       "Comment ID                                                                 \n",
       "Original Post  0.000000      0.000000         Pazluz                 NaN   \n",
       "iza7on8        0.328571      0.482143          Xivvx             99326.0   \n",
       "izc7ash       -0.050794      0.489365   Hrrrrnnngggg             85821.0   \n",
       "iza2635       -0.150000      0.750000  Amy_Macadamia             30055.0   \n",
       "izae8rg        0.083333      0.300000      rucb_alum             30307.0   \n",
       "\n",
       "              Parent Comment ID  \n",
       "Comment ID                       \n",
       "Original Post            zf54gb  \n",
       "iza7on8               t3_zf54gb  \n",
       "izc7ash               t3_zf54gb  \n",
       "iza2635               t3_zf54gb  \n",
       "izae8rg               t3_zf54gb  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import file\n",
    "Tk().withdraw()\n",
    "filename = askopenfilename()\n",
    "\n",
    "if filename.endswith('.csv'):\n",
    "    print(\"CSV file detected.\")\n",
    "    df = pd.read_csv(filename, index_col = 0)\n",
    "elif filename.endswith('.xlsx'):\n",
    "    print(\"Excel file format detected.\")\n",
    "    df = pd.read_excel(filename, index_col=0)\n",
    "else:\n",
    "    print(\"This is not a recognized file type.\")\n",
    "    exit()\n",
    "\n",
    "# cut of file\n",
    "print(\"First few lines of imported file:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all comments into a single string, clean up\n",
    "bCorrect = input(\"Does this dataframe look correct? Confirm 'yes' or 'no'.\").strip()\n",
    "if bCorrect == \"yes\":\n",
    "    s = df[\"Comment\"]\n",
    "    allComments = s.str.cat(sep=\" \")\n",
    "    allComments = allComments.replace(u'\\u201c', '').replace(u'\\u201d', '')\n",
    "    allComments = allComments.replace(u'\\u2018', '').replace(u'\\u2019', '')\n",
    "    # allComments = allComments.translate(str.maketrans('', '', string.punctuation))\n",
    "elif bCorrect == \"no\":\n",
    "    print(\"Stopping process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove contractions\n",
    "def remove_contractions(json_file = \"text-cleaner-dictionary.json\", json_key = \"contraction-joined\"):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "        for word in allComments.split():\n",
    "            if word.lower() in data:\n",
    "                allComments = allComments.replace(word, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract noun phrases\n",
    "comment = TextBlob(allComments)\n",
    "dfnp = pd.DataFrame(columns=[\"Word(s)\"])\n",
    "\n",
    "for np in comment.noun_phrases:\n",
    "    # append columns to an empty DataFrame\n",
    "    np = np.singularize()\n",
    "    insert_row = {\"Word(s)\": np}\n",
    "    dfnp = pd.concat([dfnp, pd.DataFrame([insert_row])])\n",
    "\n",
    "words_occurances = dfnp['Word(s)'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words_occurances.to_csv('/Users/p40014d/OneDrive - AholdDelhaize.com/Documents/Web Scraping/Self-Checkout - Reddit/Python Cleaned/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c4a26ec77b70a0de623b940775a788e88d8a6e9f3ab87532893bafb7eb31bc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
