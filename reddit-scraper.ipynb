{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "from datetime import date\n",
    "from textblob import TextBlob, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull security info from json file\n",
    "\n",
    "def create_reddit_object(json_file = \"reddit-login.json\", json_key = \"comment-crawler-login\"):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "        session = requests.Session()\n",
    "        session.verify = 'C:\\\\Users\\\\p40014d\\\\OneDrive - AholdDelhaize.com\\\\Documents\\\\Github Code\\\\Reddit-Web-Scraper\\\\certReddit.cer'\n",
    "\n",
    "        user_info = data[json_key][0]\n",
    "        reddit = praw.Reddit(client_id = user_info['client_id'],\n",
    "                            client_secret = user_info['client_secret'],\n",
    "                            user_agent = user_info['user_agent'],\n",
    "                            username = user_info['username'],\n",
    "                            password = user_info['password'],\n",
    "                            requestor_kwargs={'session': session})\n",
    "\n",
    "    return reddit\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new CSV file...\n",
      "Scraping Reddit comments...\n",
      "Reddit comments successfully extracted!\n"
     ]
    }
   ],
   "source": [
    "# DATA PULL\n",
    "\n",
    "reddit = create_reddit_object()\n",
    "post_id = input(\"Enter the ID from the URL:\").strip()\n",
    "today = date.today().strftime('%Y-%m-%d')\n",
    "submission = reddit.submission(id=post_id)\n",
    "subred_name = submission.subreddit.display_name\n",
    "new_csv_file_name = f'C:/Users/p40014d/OneDrive - AholdDelhaize.com/Documents/Web Scraping/Self-Checkout - Reddit/{subred_name} Source ID {post_id} Scrape Results {today}.csv'\n",
    "\n",
    "#prepare CSV file\n",
    "print(\"Creating new CSV file...\")\n",
    "try:\n",
    "    with open(new_csv_file_name, 'w', encoding = 'utf_8_sig', newline = '') as csv_file:\n",
    "        csv_write = csv.writer(csv_file)\n",
    "        csv_write.writerow(['Comment ID', 'UTC DateTime', 'Comment', 'Score', 'Polarity', 'Subjectivity', 'Username', 'User Karma (total)', 'Parent Comment ID' ])\n",
    "\n",
    "        #pull initial post's title, author, date, score\n",
    "        og_post_sentiment = TextBlob(submission.title)\n",
    "        print(\"Scraping Reddit comments...\")\n",
    "        csv_write.writerow([post_id, submission.created, submission.title, submission.score, og_post_sentiment.sentiment.polarity, og_post_sentiment.sentiment.subjectivity, submission.author, \"\", \"Original Post\"])\n",
    "\n",
    "        # loop through comments\n",
    "        submission.comments.replace_more(limit=2)\n",
    "        for comment in submission.comments.list():\n",
    "            \n",
    "            # Enter null values for [deleted] items\n",
    "            try:\n",
    "                username = comment.author.name\n",
    "            except:\n",
    "                username = \"\"\n",
    "                \n",
    "            try:\n",
    "                comment_score = comment.score\n",
    "            except:\n",
    "                comment_score = 0\n",
    "            \n",
    "            # this step is the time-waster here! takes several minutes\n",
    "            try:\n",
    "                users_score = comment.author.comment_karma\n",
    "            except:\n",
    "                users_score = 0\n",
    "\n",
    "            try:\n",
    "                comment_body = str(comment.body)\n",
    "            except:\n",
    "                comment_body = \"\"\n",
    "\n",
    "            # try to write a CSV file with new data\n",
    "            comment_sent = TextBlob(comment_body)\n",
    "            try:\n",
    "                csv_write.writerow([comment.id,\n",
    "                                    comment.created,\n",
    "                                    comment_body,\n",
    "                                    comment_score,\n",
    "                                    comment_sent.polarity,\n",
    "                                    comment_sent.subjectivity,\n",
    "                                    username,\n",
    "                                    users_score,\n",
    "                                    comment.parent_id]) #needs brackets to keep strings combined\n",
    "            except PermissionError as err:\n",
    "                print('Close all instances of the file open.')\n",
    "            except AttributeError as err:\n",
    "                print(err)\n",
    "    print(\"Reddit comments successfully extracted!\")\n",
    "except PermissionError as err:\n",
    "    print('Close all instances of the file open.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c4a26ec77b70a0de623b940775a788e88d8a6e9f3ab87532893bafb7eb31bc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
